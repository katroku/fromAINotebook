{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PYTHON FOR BEGINNERS LOL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testclass():\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "    def printname(self): #must input self\n",
    "        print(self.name)\n",
    "    #self is instance representative of the class\n",
    "    def __call__(self,name):\n",
    "        return self.name+name\n",
    "    #used so that object can be called e.g. testclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = testclass('Kat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kat\n"
     ]
    }
   ],
   "source": [
    "t.printname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analogy to BertBaseUncased above\n",
    "class testclass2():\n",
    "    def __init__(self):\n",
    "        self.tc = testclass('Katie')\n",
    "    def add(self,name):\n",
    "        return self.tc(name) #calls object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = testclass2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.add('Little') #it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Method overriding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parent(object):\n",
    "    def __init__(self):\n",
    "         self.value = 4\n",
    "    def get_value(self):\n",
    "         return self.value\n",
    "    def __type__(self):\n",
    "        return type(self.value)\n",
    "\n",
    "#child inherits from parent, overrides get_value\n",
    "class Child(Parent):\n",
    "    def get_value(self):\n",
    "        return self.value*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "c = Child()\n",
    "print(c.value)\n",
    "print(c.get_value())\n",
    "print(c.__type__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one 1\n",
      "two 2\n"
     ]
    }
   ],
   "source": [
    "def func(**stuff):\n",
    "    #collects keywords,values as dictionary\n",
    "    for i in stuff:\n",
    "        print(i,stuff[i])\n",
    "\n",
    "func(one = 1, two = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###BERT EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd577b1185bf4590bf653c6be6b6216f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566b16d8cb6b4040b94e580f0d74afee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506ff7afc1ea4694907beeedfa8c055d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "#what input is it using\n",
    "#* collects all positional arguments in a tuple\n",
    "#** collects all keyword arguments in a dictionary\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]])\n",
      "token_type_ids tensor([[0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    print(i,inputs[i])\n",
    "#input_ids are ids of tokens\n",
    "#token_type_ids are to separate questions and answers\n",
    "#attention_mask are used for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1144,  0.1937,  0.1250,  ..., -0.3827,  0.2107,  0.5407],\n",
      "         [ 0.5308,  0.3207,  0.3665,  ..., -0.0036,  0.7579,  0.0388],\n",
      "         [-0.4877,  0.8849,  0.4256,  ..., -0.6976,  0.4458,  0.1231],\n",
      "         ...,\n",
      "         [-0.7003, -0.1815,  0.3297,  ..., -0.4838,  0.0680,  0.8901],\n",
      "         [-1.0355, -0.2567, -0.0317,  ...,  0.3197,  0.3999,  0.1795],\n",
      "         [ 0.6080,  0.2610, -0.3131,  ...,  0.0311, -0.6283, -0.1994]]],\n",
      "       grad_fn=<NativeLayerNormBackward>) \n",
      "\n",
      "tensor([[-7.1946e-01, -2.1445e-01, -2.9576e-01,  3.6603e-01,  2.7968e-01,\n",
      "          2.2184e-02,  5.7299e-01,  6.2331e-02,  5.9586e-02, -9.9965e-01,\n",
      "          5.0146e-02,  4.4756e-01,  9.7612e-01,  3.3988e-02,  8.4494e-01,\n",
      "         -3.6905e-01,  9.8649e-02, -3.7169e-01,  1.7371e-01,  1.1515e-01,\n",
      "          4.4133e-01,  9.9525e-01,  3.7221e-01,  8.2881e-02,  2.1402e-01,\n",
      "          6.8965e-01, -6.1042e-01,  8.7136e-01,  9.4158e-01,  5.7372e-01,\n",
      "         -3.2187e-01,  8.6670e-03, -9.8611e-01, -2.0542e-02, -4.3756e-01,\n",
      "         -9.8012e-01,  1.1142e-01, -6.7587e-01,  1.3499e-01,  3.1130e-01,\n",
      "         -8.2997e-01,  1.9006e-01,  9.9896e-01, -3.1798e-01,  2.1517e-02,\n",
      "         -1.6531e-01, -9.9943e-01,  1.0173e-01, -8.1811e-01,  3.3119e-02,\n",
      "          3.6740e-01, -7.3230e-02, -1.4261e-01,  1.8907e-01,  2.6119e-01,\n",
      "          4.1582e-01, -2.4427e-01, -5.9846e-02, -7.3492e-02, -3.4202e-01,\n",
      "         -5.8001e-01,  2.8331e-01, -5.0513e-01, -8.1967e-01,  1.9813e-01,\n",
      "          1.9108e-01,  3.7011e-02, -1.1327e-01,  1.3472e-01, -2.1614e-01,\n",
      "          6.3494e-01,  2.4869e-02,  3.8287e-01, -8.1779e-01, -2.4874e-01,\n",
      "          8.4982e-02, -5.2998e-01,  1.0000e+00, -5.2155e-02, -9.7052e-01,\n",
      "          3.9848e-01,  2.1360e-02,  3.9035e-01,  3.5588e-01, -1.7881e-01,\n",
      "         -9.9997e-01,  2.6939e-01, -3.8057e-02, -9.8657e-01,  6.9322e-02,\n",
      "          3.9138e-01, -2.1884e-02, -9.6331e-02,  3.8545e-01, -3.4136e-01,\n",
      "         -8.0362e-02, -3.2022e-02, -3.6328e-01, -7.8130e-02,  1.9192e-02,\n",
      "         -1.3429e-01, -1.6013e-02, -5.2640e-02, -2.8006e-01,  9.3611e-02,\n",
      "         -2.2885e-01, -1.2305e-01, -1.1002e-01, -3.2808e-01,  4.0356e-01,\n",
      "          2.8048e-01, -2.0102e-01,  2.7685e-01, -9.4023e-01,  4.1756e-01,\n",
      "         -1.5473e-01, -9.7553e-01, -4.3003e-01, -9.8546e-01,  5.9158e-01,\n",
      "          3.7343e-02, -1.9320e-01,  9.1691e-01,  3.6012e-01,  1.4505e-01,\n",
      "          1.5398e-01, -1.0657e-02, -1.0000e+00, -3.1573e-01, -3.1037e-01,\n",
      "          1.6523e-01, -8.0330e-02, -9.6650e-01, -9.4546e-01,  3.6145e-01,\n",
      "          9.0138e-01, -7.2696e-02,  9.9774e-01,  3.7289e-02,  9.3599e-01,\n",
      "          2.5317e-01, -2.0185e-01,  2.9533e-02, -2.3162e-01,  3.4632e-01,\n",
      "         -1.0763e-01, -2.6565e-01,  1.0874e-01,  1.2985e-01,  2.1135e-02,\n",
      "         -9.6283e-02, -7.6358e-02, -6.5149e-02, -8.9277e-01, -2.3465e-01,\n",
      "          9.1176e-01,  7.0429e-02, -2.1429e-01,  3.8197e-01,  3.5892e-02,\n",
      "         -1.6971e-01,  7.0654e-01,  2.4045e-01,  1.5014e-01, -1.9478e-02,\n",
      "          2.1369e-01, -1.7977e-01,  3.5112e-01, -6.0260e-01,  4.1683e-01,\n",
      "          1.8090e-01, -3.2496e-02, -3.0138e-01, -9.7103e-01, -1.3917e-01,\n",
      "          3.5130e-01,  9.8326e-01,  5.2702e-01,  4.8811e-02,  1.3991e-02,\n",
      "         -6.7964e-02,  2.9718e-01, -9.4136e-01,  9.7219e-01, -2.4774e-02,\n",
      "          1.5224e-01, -1.8241e-01,  5.5584e-02, -7.7306e-01, -9.9000e-02,\n",
      "          4.7058e-01, -1.7022e-01, -7.7803e-01,  5.2833e-02, -3.7679e-01,\n",
      "         -4.1296e-02, -4.9612e-01,  1.4171e-01, -1.1803e-01, -1.8995e-01,\n",
      "          5.0383e-02,  9.0623e-01,  7.8828e-01,  5.2288e-01, -3.5274e-01,\n",
      "          2.8563e-01, -8.1494e-01, -1.9622e-01, -9.2975e-02,  5.9311e-02,\n",
      "          3.1903e-02,  9.8860e-01, -3.9452e-01,  1.1867e-01, -8.6977e-01,\n",
      "         -9.7789e-01, -1.4859e-01, -7.7064e-01, -4.0618e-03, -4.1152e-01,\n",
      "          3.2578e-01,  1.8777e-01, -2.4501e-01,  2.6668e-01, -7.9329e-01,\n",
      "         -4.8133e-01,  9.3245e-02, -1.7010e-01,  2.7043e-01, -3.5880e-02,\n",
      "          7.7973e-01,  4.6696e-01, -3.4636e-01,  5.5238e-02,  9.0312e-01,\n",
      "         -2.4115e-01, -6.4200e-01,  4.1441e-01, -9.7797e-02,  6.2983e-01,\n",
      "         -4.1787e-01,  9.4069e-01,  4.9285e-01,  3.6058e-01, -8.7901e-01,\n",
      "         -2.6726e-01, -5.4679e-01,  9.3906e-04, -1.0502e-02, -4.6837e-01,\n",
      "          3.1116e-01,  3.6999e-01,  1.3306e-01,  6.4092e-01, -3.5630e-01,\n",
      "          8.8549e-01, -8.9036e-01, -9.3865e-01, -8.1215e-01,  2.7362e-01,\n",
      "         -9.8566e-01,  4.0363e-01,  2.1223e-01, -1.4316e-01, -2.4553e-01,\n",
      "         -2.1144e-01, -9.4728e-01,  5.0806e-01, -9.6622e-02,  8.5571e-01,\n",
      "         -1.0133e-01, -6.7768e-01, -2.8500e-01, -8.9905e-01, -3.3577e-01,\n",
      "          8.9155e-02,  3.2600e-01, -2.6467e-01, -9.2032e-01,  3.4629e-01,\n",
      "          3.3430e-01,  2.1397e-01,  3.0629e-02,  9.3878e-01,  9.9986e-01,\n",
      "          9.6385e-01,  8.3159e-01,  6.2250e-01, -9.8055e-01, -7.3623e-01,\n",
      "          9.9986e-01, -7.8395e-01, -9.9998e-01, -8.7800e-01, -5.0893e-01,\n",
      "          2.3399e-02, -1.0000e+00, -6.1938e-02,  1.9563e-01, -9.0552e-01,\n",
      "         -1.4008e-01,  9.5264e-01,  7.9837e-01, -1.0000e+00,  7.6343e-01,\n",
      "          8.3670e-01, -4.5859e-01,  5.4410e-01, -2.4073e-01,  9.6085e-01,\n",
      "          1.9164e-01,  3.2135e-01, -1.3064e-02,  2.4534e-01, -5.3001e-01,\n",
      "         -5.9538e-01,  3.7464e-01, -2.1189e-01,  8.8024e-01,  1.9648e-02,\n",
      "         -3.8349e-01, -8.4779e-01,  1.4676e-02, -2.8376e-02, -4.4313e-01,\n",
      "         -9.4966e-01, -6.5704e-02, -7.2327e-02,  6.5967e-01, -1.1504e-01,\n",
      "          2.1876e-01, -5.5254e-01,  9.2219e-02, -5.0583e-01, -5.2826e-02,\n",
      "          5.1425e-01, -8.9533e-01, -1.2744e-01,  9.7844e-02, -6.0145e-01,\n",
      "         -3.1652e-02, -9.5186e-01,  9.4685e-01, -2.2341e-01,  1.8390e-01,\n",
      "          1.0000e+00,  1.1755e-01, -7.0390e-01,  3.2502e-01, -1.0898e-02,\n",
      "         -1.8308e-01,  9.9999e-01,  5.8376e-01, -9.7387e-01, -3.3783e-01,\n",
      "          2.9640e-01, -2.7002e-01, -2.2243e-01,  9.9711e-01,  1.4422e-02,\n",
      "          7.8268e-02,  3.8660e-01,  9.7787e-01, -9.8501e-01,  8.7459e-01,\n",
      "         -7.2276e-01, -9.5249e-01,  9.4567e-01,  9.1005e-01, -5.0722e-01,\n",
      "         -4.9026e-01, -1.2517e-01, -3.9076e-02,  8.8128e-02, -8.2481e-01,\n",
      "          3.8301e-01,  1.8045e-01,  5.4796e-02,  8.0041e-01, -3.3501e-01,\n",
      "         -3.9115e-01,  1.4233e-01, -9.0141e-02,  3.4585e-01,  4.4044e-01,\n",
      "          3.1045e-01, -1.3280e-01, -1.3614e-01, -3.0303e-01, -4.8794e-01,\n",
      "         -9.4950e-01,  1.0887e-01,  1.0000e+00,  6.0752e-02,  8.3374e-02,\n",
      "         -3.1302e-03,  8.5578e-02, -3.1288e-01,  2.6283e-01,  2.6870e-01,\n",
      "         -1.4267e-01, -7.4000e-01,  2.2856e-01, -7.9442e-01, -9.8812e-01,\n",
      "          4.3592e-01,  7.7229e-02, -3.8084e-02,  9.9490e-01,  3.2616e-01,\n",
      "          6.7989e-02,  8.2888e-02,  4.7390e-01, -2.1855e-01,  3.9278e-01,\n",
      "          3.7665e-02,  9.6440e-01, -1.8374e-01,  3.9259e-01,  4.3319e-01,\n",
      "         -1.8618e-01, -2.1584e-01, -4.9610e-01, -9.7025e-02, -8.8006e-01,\n",
      "          2.4995e-01, -9.3940e-01,  9.3827e-01,  3.2001e-01,  1.1919e-01,\n",
      "          7.3959e-02,  3.1273e-02,  1.0000e+00, -7.5631e-01,  3.5396e-01,\n",
      "          5.3290e-01,  3.2036e-01, -9.7538e-01, -4.7482e-01, -2.3322e-01,\n",
      "          3.5377e-02, -4.6060e-02, -1.2863e-01,  8.3798e-02, -9.5139e-01,\n",
      "          3.4663e-02,  4.5219e-03, -8.8296e-01, -9.8300e-01,  1.6468e-01,\n",
      "          3.3595e-01, -1.0217e-01, -7.0275e-01, -4.3307e-01, -5.4169e-01,\n",
      "          1.8884e-01, -5.5797e-02, -9.2162e-01,  4.4790e-01, -3.5256e-02,\n",
      "          2.1131e-01, -4.6267e-02,  4.1688e-01,  1.9311e-01,  8.2643e-01,\n",
      "          3.1897e-02,  1.8036e-02,  2.2502e-02, -5.6261e-01,  5.2690e-01,\n",
      "         -4.1523e-01, -2.0335e-01,  5.0974e-03,  1.0000e+00, -1.3769e-01,\n",
      "          4.0090e-01,  4.8581e-01,  3.0547e-01,  1.0161e-01,  1.1372e-01,\n",
      "          5.4688e-01,  1.7282e-01, -1.1611e-01,  1.1692e-01,  3.3706e-01,\n",
      "         -9.4995e-02,  3.3125e-01, -1.1600e-01,  5.5663e-02,  6.9017e-01,\n",
      "          5.2775e-01, -7.8248e-02,  7.7874e-02, -2.5570e-01,  9.5441e-01,\n",
      "          4.4725e-02,  7.5062e-02, -1.6521e-01,  9.8572e-02, -1.2673e-01,\n",
      "          4.2396e-01,  9.9999e-01,  1.4012e-01, -6.5117e-02, -9.8683e-01,\n",
      "         -3.4659e-01, -6.9549e-01,  9.9968e-01,  7.8693e-01, -6.2560e-01,\n",
      "          4.0561e-01,  5.1398e-01, -7.1927e-03,  3.7469e-01, -4.9920e-02,\n",
      "         -1.8379e-01,  1.0699e-01,  6.4271e-02,  9.4363e-01, -4.5982e-01,\n",
      "         -9.6684e-01, -4.8714e-01,  1.6233e-01, -9.2982e-01,  9.8976e-01,\n",
      "         -2.8241e-01, -3.9526e-02, -2.8969e-01,  2.2178e-01, -7.3322e-01,\n",
      "         -1.9752e-01, -9.7385e-01,  1.4625e-01,  1.7384e-02,  9.4459e-01,\n",
      "          8.0070e-02, -4.1026e-01, -7.2363e-01,  6.5494e-02,  2.9531e-01,\n",
      "         -2.0402e-01, -9.4453e-01,  9.4867e-01, -9.6224e-01,  4.1987e-01,\n",
      "          9.9992e-01,  2.0182e-01, -5.9719e-01,  6.7062e-02, -1.3560e-01,\n",
      "          1.1140e-01, -7.1071e-02,  3.3843e-01, -9.1928e-01, -1.1785e-01,\n",
      "          7.1903e-03,  9.3813e-02,  1.2718e-01, -4.2175e-01,  6.2383e-01,\n",
      "         -3.0948e-02, -3.9573e-01, -4.9911e-01,  1.9713e-01,  1.9574e-01,\n",
      "          5.2774e-01, -6.4999e-02,  3.8217e-02, -1.3764e-01,  1.3114e-01,\n",
      "         -8.2896e-01, -6.2801e-02, -1.3077e-01, -9.9745e-01,  3.8189e-01,\n",
      "         -1.0000e+00, -4.9528e-02, -3.3011e-01, -9.7048e-03,  7.4031e-01,\n",
      "          4.5588e-01, -4.3038e-02, -5.9485e-01,  3.5138e-02,  8.4290e-01,\n",
      "          7.0024e-01,  4.9503e-03,  1.5221e-01, -4.8182e-01,  3.4912e-02,\n",
      "          6.8681e-02,  5.9797e-02,  9.4147e-02,  5.7532e-01,  3.5063e-02,\n",
      "          1.0000e+00, -4.4783e-03, -3.4757e-01, -7.9309e-01,  5.7241e-02,\n",
      "         -4.8241e-02,  9.9991e-01, -3.6963e-01, -9.2729e-01,  2.2610e-01,\n",
      "         -3.2602e-01, -6.5948e-01,  2.3506e-01, -6.6027e-02, -6.2875e-01,\n",
      "         -4.7124e-01,  8.3105e-01,  4.3462e-01, -5.2237e-01,  2.1811e-01,\n",
      "         -1.1176e-01, -2.7027e-01, -6.8502e-02,  5.0503e-02,  9.8319e-01,\n",
      "          3.3888e-01,  5.6442e-01,  1.0517e-01,  6.1442e-02,  9.3666e-01,\n",
      "          7.3988e-02, -2.4528e-01, -8.5207e-02,  9.9998e-01,  1.4210e-01,\n",
      "         -8.2488e-01,  2.2405e-01, -9.2098e-01, -1.0235e-01, -8.4105e-01,\n",
      "          2.1140e-01, -3.4107e-02,  8.0942e-01,  4.9841e-03,  8.9624e-01,\n",
      "          6.7186e-02, -1.7137e-01, -2.7561e-01,  2.6385e-01,  1.9073e-01,\n",
      "         -8.6307e-01, -9.8238e-01, -9.8035e-01,  2.2370e-01, -3.5154e-01,\n",
      "          1.9181e-01,  8.9503e-02, -9.8139e-02,  8.3593e-02,  3.0373e-01,\n",
      "         -9.9998e-01,  9.0944e-01,  2.9007e-01,  4.4585e-01,  9.4631e-01,\n",
      "          4.1260e-01,  1.9621e-01,  2.4693e-01, -9.7562e-01, -7.6957e-01,\n",
      "         -1.7996e-01, -5.8601e-02,  4.2949e-01,  3.3341e-01,  8.0547e-01,\n",
      "          2.5306e-01, -4.0736e-01, -3.4585e-02,  4.1000e-01, -8.3874e-01,\n",
      "         -9.9092e-01,  3.0937e-01,  3.3917e-01, -6.2679e-01,  9.4565e-01,\n",
      "         -5.9613e-01, -1.9440e-03,  3.7971e-01, -2.2250e-01,  5.2158e-01,\n",
      "          5.9324e-01, -1.8357e-02, -6.8000e-03,  2.1554e-01,  8.2484e-01,\n",
      "          8.0068e-01,  9.7795e-01, -1.0868e-01,  4.3963e-01,  2.2388e-01,\n",
      "          2.7078e-01,  8.5065e-01, -9.2567e-01,  4.3627e-03, -3.2063e-02,\n",
      "         -1.9565e-01,  1.1169e-01, -9.4711e-02, -7.2644e-01,  6.3986e-01,\n",
      "         -1.7955e-01,  4.2939e-01, -2.0787e-01,  2.2294e-01, -2.3857e-01,\n",
      "          6.7195e-02, -5.1772e-01, -3.6389e-01,  5.3170e-01,  5.3485e-02,\n",
      "          8.5309e-01,  6.4611e-01,  1.2341e-02, -2.4756e-01,  1.4719e-02,\n",
      "         -5.3294e-02, -9.2566e-01,  5.0771e-01,  1.2492e-01,  2.1457e-01,\n",
      "         -6.7959e-02, -2.7113e-01,  9.0946e-01, -1.9032e-01, -2.1274e-01,\n",
      "         -6.4847e-02, -4.3871e-01,  6.3751e-01, -2.1017e-01, -2.9291e-01,\n",
      "         -3.1616e-01,  5.4117e-01,  1.6768e-01,  9.9424e-01, -9.4508e-02,\n",
      "         -2.9022e-01, -2.1877e-03, -1.5720e-01,  2.8317e-01, -2.9364e-01,\n",
      "         -9.9998e-01,  1.4066e-01,  9.1605e-02,  1.1457e-01, -2.1965e-01,\n",
      "          3.0746e-01, -5.7719e-02, -8.7692e-01, -9.3891e-02,  2.2809e-01,\n",
      "          3.8767e-02, -3.2828e-01, -3.1138e-01,  4.1117e-01,  4.6004e-01,\n",
      "          5.5266e-01,  7.2535e-01,  2.5635e-01,  5.2958e-01,  4.7964e-01,\n",
      "         -1.0402e-01, -5.4204e-01,  8.4934e-01]], grad_fn=<TanhBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in outputs:\n",
    "    print(i,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###BERT Finetuned Model to predict sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae011416ac754238ae1ec68d1846357d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ef4218acfc45dfb7c9e6a6f29fab78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6a1e7e5c049bf83f79cfb40946856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The input has a total of 70 tokens.\n",
      "[CLS]           101\n",
      "how           2,129\n",
      "many          2,116\n",
      "parameters   11,709\n",
      "does          2,515\n",
      "bert         14,324\n",
      "-             1,011\n",
      "large         2,312\n",
      "have          2,031\n",
      "?             1,029\n",
      "\n",
      "[SEP]           102\n",
      "\n",
      "bert         14,324\n",
      "-             1,011\n",
      "large         2,312\n",
      "is            2,003\n",
      "really        2,428\n",
      "big           2,502\n",
      ".             1,012\n",
      ".             1,012\n",
      ".             1,012\n",
      "it            2,009\n",
      "has           2,038\n",
      "24            2,484\n",
      "-             1,011\n",
      "layers        9,014\n",
      "and           1,998\n",
      "an            2,019\n",
      "em            7,861\n",
      "##bed         8,270\n",
      "##ding        4,667\n",
      "size          2,946\n",
      "of            1,997\n",
      "1             1,015\n",
      ",             1,010\n",
      "02            6,185\n",
      "##4           2,549\n",
      ",             1,010\n",
      "for           2,005\n",
      "a             1,037\n",
      "total         2,561\n",
      "of            1,997\n",
      "340          16,029\n",
      "##m           2,213\n",
      "parameters   11,709\n",
      "!               999\n",
      "altogether   10,462\n",
      "it            2,009\n",
      "is            2,003\n",
      "1             1,015\n",
      ".             1,012\n",
      "34            4,090\n",
      "##gb         18,259\n",
      ",             1,010\n",
      "so            2,061\n",
      "expect        5,987\n",
      "it            2,009\n",
      "to            2,000\n",
      "take          2,202\n",
      "a             1,037\n",
      "couple        3,232\n",
      "minutes       2,781\n",
      "to            2,000\n",
      "download      8,816\n",
      "to            2,000\n",
      "your          2,115\n",
      "cola         15,270\n",
      "##b           2,497\n",
      "instance      6,013\n",
      ".             1,012\n",
      "\n",
      "[SEP]           102\n",
      "\n",
      "Answer: \"340m\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "question = \"How many parameters does BERT-large have?\"\n",
    "answer_text = \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\"\n",
    "\n",
    "# Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "#To feed into BERT, concatenate question,answer together and place the special [SEP] token in between\n",
    "input_ids = tokenizer.encode(question, answer_text)\n",
    "print('The input has a total of {:} tokens.'.format(len(input_ids)))\n",
    "\n",
    "#to see the tokens\n",
    "# BERT only needs the token IDs, but for the purpose of inspecting the \n",
    "# tokenizer's behavior, let's also get the token strings and display them.\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# For each token and its id...\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    \n",
    "    # If this is the [SEP] token, add some space around it to make it stand out.\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "    \n",
    "    # Print the token string and its ID in two columns.\n",
    "    print('{:<12} {:>6,}'.format(token, id))\n",
    "\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "#token_type_id\n",
    "# Search the input_ids for the first instance of the `[SEP]` token.\n",
    "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "# The number of segment A tokens includes the [SEP] token istelf.\n",
    "num_seg_a = sep_index + 1\n",
    "\n",
    "# The remainder are segment B.\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "# Construct the list of 0s and 1s.\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "# There should be a segment_id for every input token.\n",
    "assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "#padding for batch only\n",
    "\n",
    "# Run our example through the model.\n",
    "start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                 token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "#PRINT ANSWER\n",
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "answer_start = torch.argmax(start_scores)\n",
    "answer_end = torch.argmax(end_scores)\n",
    "# Start with the first token.\n",
    "answer = tokens[answer_start]\n",
    "\n",
    "# Select the remaining answer tokens and join them with whitespace.\n",
    "for i in range(answer_start + 1, answer_end + 1):\n",
    "    \n",
    "    # If it's a subword token, then recombine it with the previous token.\n",
    "    if tokens[i][0:2] == '##':\n",
    "        answer += tokens[i][2:]\n",
    "    \n",
    "    # Otherwise, add a space then the token.\n",
    "    else:\n",
    "        answer += ' ' + tokens[i]\n",
    "\n",
    "print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2129,\n",
       " 2116,\n",
       " 11709,\n",
       " 2515,\n",
       " 14324,\n",
       " 1011,\n",
       " 2312,\n",
       " 2031,\n",
       " 1029,\n",
       " 102,\n",
       " 14324,\n",
       " 1011,\n",
       " 2312,\n",
       " 2003,\n",
       " 2428,\n",
       " 2502,\n",
       " 1012,\n",
       " 1012,\n",
       " 1012,\n",
       " 2009,\n",
       " 2038,\n",
       " 2484,\n",
       " 1011,\n",
       " 9014,\n",
       " 1998,\n",
       " 2019,\n",
       " 7861,\n",
       " 8270,\n",
       " 4667,\n",
       " 2946,\n",
       " 1997,\n",
       " 1015,\n",
       " 1010,\n",
       " 6185,\n",
       " 2549,\n",
       " 1010,\n",
       " 2005,\n",
       " 1037,\n",
       " 2561,\n",
       " 1997,\n",
       " 16029,\n",
       " 2213,\n",
       " 11709,\n",
       " 999,\n",
       " 10462,\n",
       " 2009,\n",
       " 2003,\n",
       " 1015,\n",
       " 1012,\n",
       " 4090,\n",
       " 18259,\n",
       " 1010,\n",
       " 2061,\n",
       " 5987,\n",
       " 2009,\n",
       " 2000,\n",
       " 2202,\n",
       " 1037,\n",
       " 3232,\n",
       " 2781,\n",
       " 2000,\n",
       " 8816,\n",
       " 2000,\n",
       " 2115,\n",
       " 15270,\n",
       " 2497,\n",
       " 6013,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids  #inputs= question,textbody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer start\n",
      "1 : 0.05303548276424408\n",
      "340 : 6.425591468811035\n",
      "Answer end\n",
      "##4 : 0.795249879360199\n",
      "340 : 2.7500686645507812\n",
      "##m : 5.464432239532471\n",
      "parameters : 4.121987819671631\n",
      "! : 1.2127259969711304\n"
     ]
    }
   ],
   "source": [
    "print('Answer start')\n",
    "for t,s in zip(tokens,start_scores.detach().numpy().flatten()):\n",
    "    if s>0:\n",
    "        print(f'{t} : {s}')\n",
    "\n",
    "print('Answer end')\n",
    "for t,e in zip(tokens,end_scores.detach().numpy().flatten()):\n",
    "    if e>0:\n",
    "        print(f'{t} : {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, answer_text)\n",
    "\n",
    "    # Report how long the input sequence is.  Inclu\n",
    "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example question through the model.\n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We introduce a new language representation model called BERT, which stands for\n",
      "Bidirectional Encoder Representations from Transformers. Unlike recent language\n",
      "representation models (Peters et al., 2018a; Radford et al., 2018), BERT is\n",
      "designed to pretrain deep bidirectional representations from unlabeled text by\n",
      "jointly conditioning on both left and right context in all layers. As a result,\n",
      "the pre-trained BERT model can be finetuned with just one additional output\n",
      "layer to create state-of-the-art models for a wide range of tasks, such as\n",
      "question answering and language inference, without substantial taskspecific\n",
      "architecture modifications. BERT is conceptually simple and empirically\n",
      "powerful. It obtains new state-of-the-art results on eleven natural language\n",
      "processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute\n",
      "improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1\n",
      "question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD\n",
      "v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Wrap text to 80 characters.\n",
    "wrapper = textwrap.TextWrapper(width=80) \n",
    "\n",
    "bert_abstract = \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\n",
    "\n",
    "print(wrapper.fill(bert_abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 258 tokens.\n",
      "\n",
      "Answer: \"bidirectional encoder representations from transformers\"\n"
     ]
    }
   ],
   "source": [
    "question = \"What does the 'B' in BERT stand for?\"\n",
    "\n",
    "answer_question(question, bert_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 253 tokens.\n",
      "\n",
      "Answer: \"bert\"\n"
     ]
    }
   ],
   "source": [
    "answer_question('What is the new language model', bert_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 254 tokens.\n",
      "\n",
      "Answer: \"peters et al . , 2018a ; radford et al . , 2018\"\n"
     ]
    }
   ],
   "source": [
    "answer_question('What are the recent language models?', bert_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 252 tokens.\n",
      "\n",
      "Answer: \"pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers\"\n"
     ]
    }
   ],
   "source": [
    "answer_question('How does bert work?', bert_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the beginning was the Word, and the Word was with God, and the Word was God.\n",
      "2 He was with God in the beginning. 3 Through him all things were made; without\n",
      "him nothing was made that has been made. 4 In him was life, and that life was\n",
      "the light of all mankind. 5 The light shines in the darkness, and the darkness\n",
      "has not overcome[a] it.6 There was a man sent from God whose name was John. 7 He\n",
      "came as a witness to testify concerning that light, so that through him all\n",
      "might believe. 8 He himself was not the light; he came only as a witness to the\n",
      "light.9 The true light that gives light to everyone was coming into the world.\n",
      "10 He was in the world, and though the world was made through him, the world did\n",
      "not recognize him. 11 He came to that which was his own, but his own did not\n",
      "receive him. 12 Yet to all who did receive him, to those who believed in his\n",
      "name, he gave the right to become children of God— 13 children born not of\n",
      "natural descent, nor of human decision or a husband’s will, but born of God.14\n",
      "The Word became flesh and made his dwelling among us. We have seen his glory,\n",
      "the glory of the one and only Son, who came from the Father, full of grace and\n",
      "truth.\n"
     ]
    }
   ],
   "source": [
    "bert_abstract2 = 'In the beginning was the Word, and the Word was with God, and the Word was God. 2 He was with God in the beginning. 3 Through him all things were made; without him nothing was made that has been made. 4 In him was life, and that life was the light of all mankind. 5 The light shines in the darkness, and the darkness has not overcome[a] it.6 There was a man sent from God whose name was John. 7 He came as a witness to testify concerning that light, so that through him all might believe. 8 He himself was not the light; he came only as a witness to the light.9 The true light that gives light to everyone was coming into the world. 10 He was in the world, and though the world was made through him, the world did not recognize him. 11 He came to that which was his own, but his own did not receive him. 12 Yet to all who did receive him, to those who believed in his name, he gave the right to become children of God— 13 children born not of natural descent, nor of human decision or a husband’s will, but born of God.14 The Word became flesh and made his dwelling among us. We have seen his glory, the glory of the one and only Son, who came from the Father, full of grace and truth.' \n",
    "print(wrapper.fill(bert_abstract2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 290 tokens.\n",
      "\n",
      "Answer: \"in the beginning was the word , and the word was with god , and the word was god . 2 he was with god in the beginning\"\n"
     ]
    }
   ],
   "source": [
    "answer_question('what is the paragraph talking about?', bert_abstract2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
